{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# åŸºç¡€ç»„ä»¶ä¹‹Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TokenizeråŸºæœ¬ä½¿ç”¨æ–¹æ³•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pika/App/miniconda3/envs/transformers/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen = \"å¼±å°çš„æˆ‘ä¹Ÿæœ‰å¤§æ¢¦æƒ³!\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### åŠ è½½ä¸ä¿å­˜: `from_pretrained` / `save_pretrained`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='uer/roberta-base-finetuned-dianping-chinese', vocab_size=21128, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ä»HuggingFaceåŠ è½½ï¼Œè¾“å…¥æ¨¡å‹åç§°ï¼Œå³å¯åŠ è½½å¯¹äºçš„åˆ†è¯å™¨\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"uer/roberta-base-finetuned-dianping-chinese\")\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./roberta_tokenizer/tokenizer_config.json',\n",
       " './roberta_tokenizer/special_tokens_map.json',\n",
       " './roberta_tokenizer/vocab.txt',\n",
       " './roberta_tokenizer/added_tokens.json',\n",
       " './roberta_tokenizer/tokenizer.json')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenizer ä¿å­˜åˆ°æœ¬åœ°\n",
    "tokenizer.save_pretrained(\"./roberta_tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='./roberta_tokenizer/', vocab_size=21128, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ä»æœ¬åœ°åŠ è½½tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./roberta_tokenizer/\")\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, '[PAD]')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pad_token_id, tokenizer.pad_token"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### å¥å­åˆ†è¯: `tokenize`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['å¼±', 'å°', 'çš„', 'æˆ‘', 'ä¹Ÿ', 'æœ‰', 'å¤§', 'æ¢¦', 'æƒ³', '!']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer.tokenize(sen)\n",
    "tokens"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### æŸ¥çœ‹è¯å…¸: `vocab`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'##å¸': 14486,\n",
       " 'pizza': 10315,\n",
       " '##å€¶': 14021,\n",
       " '##å¾´': 15603,\n",
       " 'ng': 8885,\n",
       " '##æ‡‘': 15806,\n",
       " '##è“‰': 18957,\n",
       " '##å¥§': 15010,\n",
       " '##æ°': 16751,\n",
       " '##è–¦': 19013,\n",
       " '##et': 8418,\n",
       " 'æ»™': 4002,\n",
       " 'ç´”': 5155,\n",
       " 'âˆ™': 379,\n",
       " '##ç–¡': 17607,\n",
       " '##èŠ': 18755,\n",
       " '##ory': 9428,\n",
       " 'è®¸': 6387,\n",
       " 'ç€': 4104,\n",
       " 'ã«ãªã‚‹': 9322,\n",
       " '##\\u2028': 13502,\n",
       " '##æ¹§': 17020,\n",
       " 'de': 8363,\n",
       " '##å®•': 15190,\n",
       " '##è': 18836,\n",
       " '##éª‡': 20794,\n",
       " '##å»': 14377,\n",
       " '##æ“²': 16153,\n",
       " '##ç›§': 17735,\n",
       " '##é€€': 19899,\n",
       " '265': 8689,\n",
       " '##é’¾': 20242,\n",
       " '##å¿': 14042,\n",
       " 'è…': 5822,\n",
       " 'é„º': 6976,\n",
       " '##ç°‡': 18134,\n",
       " 'å“': 1513,\n",
       " 'å”·': 1550,\n",
       " 'èœˆ': 6048,\n",
       " 'å¨“': 2022,\n",
       " 'æ¯': 3680,\n",
       " '900': 8567,\n",
       " 'è—“': 5968,\n",
       " 'è„‚': 5544,\n",
       " 'ç“¶': 4486,\n",
       " '##è„š': 18615,\n",
       " 'é©­': 7717,\n",
       " '##ã€': 13656,\n",
       " '##æ™º': 16312,\n",
       " 'ç¼': 5352,\n",
       " 'æ‚¼': 2656,\n",
       " 'éƒµ': 6960,\n",
       " '##æ®ƒ': 16707,\n",
       " 'cafe': 8377,\n",
       " '##è±š': 19552,\n",
       " 'è›‡': 6026,\n",
       " 'valley': 11994,\n",
       " 'è•»': 5944,\n",
       " 'å¢—': 1868,\n",
       " 'è¾®': 6799,\n",
       " 'è£”': 6167,\n",
       " '##è§': 19290,\n",
       " '##çŒ´': 17404,\n",
       " '[unused86]': 86,\n",
       " 'å¼': 2459,\n",
       " '##èŒ‚': 18801,\n",
       " 'è¨•': 6247,\n",
       " '3a': 10667,\n",
       " '##æ£±': 16539,\n",
       " 'æ†': 2986,\n",
       " '##ç²': 17443,\n",
       " 'å·': 2336,\n",
       " '##2d': 12675,\n",
       " '##è´¦': 19629,\n",
       " '##ç“¢': 17536,\n",
       " '##è¸': 19732,\n",
       " 'å¨': 1370,\n",
       " 'åŠ³': 1227,\n",
       " '##ple': 10383,\n",
       " '##qi': 11451,\n",
       " 'é³¶': 7856,\n",
       " '##å€¬': 14019,\n",
       " 'è°': 6455,\n",
       " '##è§€': 19280,\n",
       " '##é–¾': 20349,\n",
       " 'å°½': 2226,\n",
       " '##ğŸ˜': 21127,\n",
       " '1929': 9792,\n",
       " '##ãŠã‚Šã¾ã™': 9797,\n",
       " 'å‚€': 986,\n",
       " 'å µ': 1843,\n",
       " 'ssh': 11678,\n",
       " 'è©®': 6280,\n",
       " 'golden': 12746,\n",
       " 'é´•': 7858,\n",
       " 'si': 10883,\n",
       " 'å‡‹': 1118,\n",
       " 'æ’ˆ': 3051,\n",
       " 'éº½': 7939,\n",
       " 'fks': 10044,\n",
       " 'ç„Š': 4184,\n",
       " 'ç‘ª': 4454,\n",
       " 'insee': 11513,\n",
       " 'ã‚µã‚¤ãƒˆ': 11572,\n",
       " '##æ‡¿': 15817,\n",
       " '##Ğµ': 13406,\n",
       " 'ãªã¨': 9744,\n",
       " 'å´´': 2311,\n",
       " '##ä½¥': 13933,\n",
       " '##é¦ˆ': 20725,\n",
       " '##æ£‹': 16527,\n",
       " '##ÃŸ': 13361,\n",
       " 'ã—': 547,\n",
       " 'systems': 12451,\n",
       " '##è¡': 19179,\n",
       " '##ndy': 11373,\n",
       " '##æ²': 16004,\n",
       " 'çŸ¥': 4761,\n",
       " 'android': 8254,\n",
       " 'ç›†': 4658,\n",
       " '##xure': 12622,\n",
       " 'è’Ÿ': 5888,\n",
       " 'ed': 9599,\n",
       " 'å±': 2241,\n",
       " '##æœª': 16370,\n",
       " 'å³': 1425,\n",
       " 'ç¦…': 4883,\n",
       " 'fc2': 11362,\n",
       " '##è´–': 19619,\n",
       " '##ãŠ': 8345,\n",
       " '##é—·': 20372,\n",
       " 'å…„': 1040,\n",
       " 'å¼µ': 2484,\n",
       " '##46': 9340,\n",
       " '##ç´Š': 18207,\n",
       " 'è‰‹': 5674,\n",
       " '1916': 10772,\n",
       " 'å °': 1840,\n",
       " '##tis': 10827,\n",
       " '##è¡©': 19192,\n",
       " '##å¼•': 15528,\n",
       " '##è§ˆ': 19286,\n",
       " 'ç–¼': 4563,\n",
       " '##éŠ‘': 20125,\n",
       " 'è´£': 6569,\n",
       " '##åŒ¹': 14333,\n",
       " 'é–¥': 7285,\n",
       " '425': 11993,\n",
       " '##éš†': 20441,\n",
       " 'ç»˜': 5313,\n",
       " '347': 12936,\n",
       " 'ã†': 666,\n",
       " '##â„ƒ': 8320,\n",
       " 'æ‡': 3355,\n",
       " '##pmlast': 12138,\n",
       " '##å„•': 14085,\n",
       " '##ç¯©': 18129,\n",
       " 'cam': 12722,\n",
       " 'æŸ”': 3382,\n",
       " '##å': 14458,\n",
       " 'æŠ¤': 2844,\n",
       " 'want': 12733,\n",
       " '##ç›±': 17739,\n",
       " 'æ¶¯': 3889,\n",
       " 'news': 8501,\n",
       " 'æŠ“': 2831,\n",
       " '30': 8114,\n",
       " '##Ğ°': 11318,\n",
       " 'å”¸': 1551,\n",
       " 'nginx': 12576,\n",
       " '##è–': 18861,\n",
       " 'ä¼•': 829,\n",
       " 'æ§': 3542,\n",
       " '##nsis': 12263,\n",
       " 'å•²': 1576,\n",
       " '##æ¢¢': 16513,\n",
       " '##bot': 10119,\n",
       " '##åŠ²': 14283,\n",
       " '##æ³„': 16843,\n",
       " '##ç¥Ÿ': 17926,\n",
       " 'å—…': 1618,\n",
       " 'èœ€': 6043,\n",
       " '##å¾½': 15608,\n",
       " 'è¤¶': 6195,\n",
       " 'pci': 10773,\n",
       " '##é—¯': 20367,\n",
       " 'á…£': 306,\n",
       " '##read': 10314,\n",
       " 'å¦®': 1984,\n",
       " 'b1': 9338,\n",
       " '##ç†Ÿ': 17282,\n",
       " '##é§': 20745,\n",
       " 'çŒ·': 4349,\n",
       " 'red': 9276,\n",
       " '##é˜…': 20382,\n",
       " 'æ®‰': 3653,\n",
       " 'æ‹Ÿ': 2877,\n",
       " 'æ”£': 3112,\n",
       " '##æ¬ ': 16669,\n",
       " 'é¤Œ': 7622,\n",
       " '##æ…‹': 15763,\n",
       " '[unused14]': 14,\n",
       " 'å¢': 1334,\n",
       " '##é³³': 20911,\n",
       " 'éš ': 7398,\n",
       " '##ä¾ˆ': 13947,\n",
       " '##è®¿': 19450,\n",
       " 'æ¥¼': 3517,\n",
       " 'ï¼™': 8037,\n",
       " 'æ•Œ': 3127,\n",
       " '##bor': 12268,\n",
       " 'joy': 12668,\n",
       " '##é¦­': 20737,\n",
       " 'å£': 1366,\n",
       " '##ncy': 10518,\n",
       " '##æ': 16388,\n",
       " 'å³‡': 2280,\n",
       " '##è¤“': 19245,\n",
       " 'æ¼”': 4028,\n",
       " 'æ±²': 3744,\n",
       " 'æ¤°': 3496,\n",
       " 'ç‰Œ': 4277,\n",
       " 'ï¼': 8013,\n",
       " '##vis': 11233,\n",
       " 'area': 13224,\n",
       " '4': 125,\n",
       " '##é…©': 20047,\n",
       " 'chang': 11680,\n",
       " '##è‘«': 18929,\n",
       " '119': 9031,\n",
       " '##æ»¡': 17064,\n",
       " 'ä¼¤': 839,\n",
       " '##çº±': 18342,\n",
       " 'è ¹': 6115,\n",
       " '##è': 18529,\n",
       " '##å ‡': 14889,\n",
       " 'çªº': 4983,\n",
       " 'å…': 1038,\n",
       " 'è‘—': 5865,\n",
       " 'dram': 10664,\n",
       " '590': 11210,\n",
       " 'ä¸Š': 677,\n",
       " 'jack': 9850,\n",
       " '##ve': 8519,\n",
       " '##å‹§': 14307,\n",
       " '##å°‡': 15257,\n",
       " '##æ': 16415,\n",
       " 'åˆ': 1394,\n",
       " 'æ®‡': 3652,\n",
       " '##36': 9159,\n",
       " 'ç©º': 4958,\n",
       " '##æ¥': 16027,\n",
       " 'beauty': 9445,\n",
       " 'æ½”': 4049,\n",
       " 'ç¾¿': 5418,\n",
       " 'm5': 12802,\n",
       " '##æ¯’': 16738,\n",
       " 'suite': 11420,\n",
       " 'ã£ã¦ã„ã‚‹': 11859,\n",
       " '386': 12303,\n",
       " '##ç®‡': 18100,\n",
       " '##æ°ª': 16768,\n",
       " '##ç´“': 18211,\n",
       " '##åŒ¾': 14336,\n",
       " '##Øª': 13430,\n",
       " 'åŠ£': 1219,\n",
       " '##å—²': 14697,\n",
       " 'é‘«': 7144,\n",
       " 'ã‚ªãƒ¼ãƒ•ãƒ³5': 11810,\n",
       " '1894': 12221,\n",
       " 'ï¹•': 8004,\n",
       " 'mix': 9678,\n",
       " '##gt': 12429,\n",
       " '##åŠ¾': 14288,\n",
       " '##ç¥º': 17935,\n",
       " '##è £': 19169,\n",
       " 'vive': 10167,\n",
       " '##è™Ÿ': 19055,\n",
       " 'æ“¢': 3091,\n",
       " 'è¬—': 6339,\n",
       " 'è¿´': 6836,\n",
       " 'dollars': 9448,\n",
       " 'æ‹‰': 2861,\n",
       " 'ç´¯': 5168,\n",
       " 'yang': 12086,\n",
       " '5d': 10406,\n",
       " 'ç¬”': 5011,\n",
       " '##Ñ†': 13421,\n",
       " '##å…': 14106,\n",
       " 'è†': 5769,\n",
       " '314': 11725,\n",
       " '##å‰¿': 14261,\n",
       " '##çœ': 17772,\n",
       " 'äº‰': 751,\n",
       " 'january': 9768,\n",
       " 'æ‹¼': 2894,\n",
       " 'å¸ƒ': 2357,\n",
       " 'è³¼': 6554,\n",
       " '00': 8136,\n",
       " '##æ©«': 16642,\n",
       " '##è®Š': 19422,\n",
       " 'ä¾µ': 909,\n",
       " '##è²¶': 19581,\n",
       " 'maker': 11389,\n",
       " '##è¸ª': 19736,\n",
       " '##é“…': 20249,\n",
       " '##é¾ˆ': 21036,\n",
       " '##æ„': 15744,\n",
       " '##æ†': 16043,\n",
       " '##æ…°': 15777,\n",
       " 'è‘¯': 5875,\n",
       " 'é¶´': 7874,\n",
       " '##é': 20160,\n",
       " '##é›¨': 20490,\n",
       " '##é‘¼': 20204,\n",
       " '##ube': 10957,\n",
       " '##52': 9364,\n",
       " '##ç—Š': 17628,\n",
       " '##æ ': 16396,\n",
       " 'é¹½': 7921,\n",
       " '##çš': 17700,\n",
       " '##è¿‡': 19871,\n",
       " 'ç»­': 5330,\n",
       " '##unch': 11294,\n",
       " 'ç¯“': 5066,\n",
       " '##ann': 12464,\n",
       " '##â˜': 13621,\n",
       " '##ç’‡': 17519,\n",
       " 'ä¸‘': 682,\n",
       " 'ç§¸': 4918,\n",
       " 'è£±': 6177,\n",
       " '##æ„•': 15750,\n",
       " 'ç€§': 4113,\n",
       " 'å¾ ': 2538,\n",
       " '##ãƒ˜': 13693,\n",
       " 'é¥': 7644,\n",
       " '##å½¥': 15560,\n",
       " ',': 117,\n",
       " '##7': 8161,\n",
       " '##â‘©': 13565,\n",
       " 'æƒ¦': 2671,\n",
       " 'ã­': 560,\n",
       " '##ç›¯': 17738,\n",
       " '##å“': 14558,\n",
       " 'kicstart2': 12614,\n",
       " '##æ®¼': 16727,\n",
       " 'é”®': 7241,\n",
       " 'è–ª': 5959,\n",
       " '##ç…’': 17261,\n",
       " '##ç£…': 17886,\n",
       " '##è': 19127,\n",
       " 'è™”': 5992,\n",
       " 'lg': 8589,\n",
       " 'å˜‰': 1649,\n",
       " 'æ‡ˆ': 2745,\n",
       " '##ãƒ¼ã‚¿': 12219,\n",
       " 'ï¼½': 8047,\n",
       " '##ç«': 18050,\n",
       " '##2007': 10604,\n",
       " '##og': 10800,\n",
       " '##èš': 18528,\n",
       " 'ac': 9226,\n",
       " 'mall': 9628,\n",
       " 'ç¶“': 5195,\n",
       " '540': 10972,\n",
       " '##æ ƒ': 16457,\n",
       " '##é´': 19961,\n",
       " '##é‹': 20159,\n",
       " '##ï¹¡': 21068,\n",
       " 'è°': 6452,\n",
       " '##å¯Ÿ': 15232,\n",
       " '##ä¸': 13737,\n",
       " '9985': 12839,\n",
       " '##éº': 20985,\n",
       " 'è¢œ': 6154,\n",
       " 'å…½': 1077,\n",
       " 'g20': 9789,\n",
       " 'éŒ¶': 7100,\n",
       " 'x': 166,\n",
       " 'çŒ': 4340,\n",
       " 'é˜ª': 7341,\n",
       " '##å†³': 14161,\n",
       " 'å•±': 1575,\n",
       " 'æ»¿': 4021,\n",
       " 'bt': 8364,\n",
       " 'tiffany': 11509,\n",
       " '##æ»': 17062,\n",
       " '##á„€': 13454,\n",
       " 'banner': 13256,\n",
       " 'é¡º': 7556,\n",
       " 'à¸': 276,\n",
       " 'èˆ–': 5655,\n",
       " '##ç³': 17489,\n",
       " '##è¨': 19134,\n",
       " '2mm': 12287,\n",
       " '##å¾—': 15590,\n",
       " 'george': 9897,\n",
       " 'ç¼½': 5376,\n",
       " '433': 13131,\n",
       " 'ä¿š': 923,\n",
       " '595': 13302,\n",
       " '##ç¾¤': 18465,\n",
       " 'æ›´': 3291,\n",
       " '##ä½»': 13941,\n",
       " '##é”¢': 20292,\n",
       " '##ãŸã‚ã«': 12260,\n",
       " '##æ¸¥': 17001,\n",
       " '##ien': 12023,\n",
       " '##2009': 9948,\n",
       " '##åŒ': 14320,\n",
       " '##è¼ƒ': 19790,\n",
       " '##é¢±': 20650,\n",
       " 'comâ„¢': 10921,\n",
       " '##å¿': 14378,\n",
       " '##éˆ•': 20103,\n",
       " '##hai': 11828,\n",
       " '##æ™': 16300,\n",
       " 'æ¶¤': 3882,\n",
       " 'è¤‚': 6184,\n",
       " 'á…¡': 304,\n",
       " '##æµ’': 16905,\n",
       " '##æ·…': 16954,\n",
       " 'æ’': 2608,\n",
       " 'é‘½': 7148,\n",
       " 'æ²«': 3773,\n",
       " '1978': 8774,\n",
       " 'rom': 8891,\n",
       " 'thunder': 11322,\n",
       " '##æŒº': 15980,\n",
       " '##èšµ': 19080,\n",
       " '##è®¸': 19444,\n",
       " '##ç’': 17413,\n",
       " 'è¾»': 6806,\n",
       " 'çº”': 5269,\n",
       " 'æŸš': 3384,\n",
       " 'ï½°': 8087,\n",
       " 'ky': 11096,\n",
       " '##é›»': 20499,\n",
       " 'film': 11149,\n",
       " '##å“€': 14557,\n",
       " '##ial': 9501,\n",
       " '##æ½›': 17108,\n",
       " 'ç¼': 4133,\n",
       " 'ï¼•ï¼': 12869,\n",
       " '##å¤”': 14967,\n",
       " '##é•Œ': 20311,\n",
       " 'urn': 11584,\n",
       " 'é†¯': 7018,\n",
       " 'â•‘': 439,\n",
       " '##vc': 12077,\n",
       " 'ä¸¥': 698,\n",
       " 'å': 1777,\n",
       " 'æ€¡': 2592,\n",
       " 'day': 8542,\n",
       " 'bloomberg': 10313,\n",
       " 'can': 9109,\n",
       " '##ã‚¿': 11011,\n",
       " '##å‰‘': 14244,\n",
       " '##é’': 20212,\n",
       " '##é¤Š': 20678,\n",
       " 'rn': 11998,\n",
       " '##èŒ': 18800,\n",
       " '##çŸ¾': 17827,\n",
       " '##é¸¿': 20953,\n",
       " 'belle': 13058,\n",
       " 'rich': 13210,\n",
       " '##è¿„': 19869,\n",
       " '##å…°': 14122,\n",
       " 'ä½•': 862,\n",
       " 'âœ”': 497,\n",
       " '##ç–®': 17612,\n",
       " 'ç²˜': 5111,\n",
       " '##å²–': 15322,\n",
       " '##ã¾ã™': 8643,\n",
       " '##å¯': 14480,\n",
       " 'á…¦': 308,\n",
       " 'è•': 6071,\n",
       " 'éœ': 7454,\n",
       " 'ã›ã¾ã™': 10046,\n",
       " '##ä½˜': 13921,\n",
       " 'ç­': 4361,\n",
       " 'å²©': 2272,\n",
       " 'space': 9634,\n",
       " 'ä½¼': 885,\n",
       " '##âœ–': 13635,\n",
       " '##ç­²': 18094,\n",
       " 'æˆ¿': 2791,\n",
       " 'é´': 6904,\n",
       " '##â‰¤': 13545,\n",
       " '##ç²‘': 18164,\n",
       " 'men': 11305,\n",
       " 'æ‚š': 2639,\n",
       " '##æ»‹': 17053,\n",
       " '##è¢': 19143,\n",
       " 'è“‹': 5901,\n",
       " 'æ±': 3734,\n",
       " 'kate': 11058,\n",
       " '1986': 8629,\n",
       " '##è ': 18864,\n",
       " '30g': 12008,\n",
       " '##ç®': 17486,\n",
       " 'æ¨º': 3573,\n",
       " '##à¹€': 13450,\n",
       " 'bay': 10251,\n",
       " '##ssion': 12726,\n",
       " '##gs': 9726,\n",
       " '##ãªã': 10395,\n",
       " '##è¼': 19797,\n",
       " 'å›¤': 1732,\n",
       " '##å¤': 14965,\n",
       " 'office': 8628,\n",
       " 'é˜»': 7349,\n",
       " '##ford': 10283,\n",
       " '##ç°': 17419,\n",
       " 'ç—¿': 4594,\n",
       " 'Ø¯': 265,\n",
       " '539': 12995,\n",
       " '##é—°': 20368,\n",
       " '##è‰²': 18739,\n",
       " 'éš‹': 7387,\n",
       " '##èŠª': 18760,\n",
       " '##è«’': 19372,\n",
       " 'çº': 5266,\n",
       " '##æ‰': 16014,\n",
       " 'é™›': 7363,\n",
       " 'é§': 7692,\n",
       " 'é¼¾': 7966,\n",
       " 'some': 13048,\n",
       " '##2': 8144,\n",
       " 'è•¨': 5938,\n",
       " '##care': 11014,\n",
       " '##mbps': 12399,\n",
       " '##å¤¥': 14976,\n",
       " '##æ¤½': 16555,\n",
       " '##æ²­': 16831,\n",
       " '##å­˜': 15157,\n",
       " 'è†¾': 5616,\n",
       " '##æº¥': 17038,\n",
       " '##å®›': 15195,\n",
       " 'èŒ¼': 5766,\n",
       " '##è Ÿ': 19166,\n",
       " 'ç½•': 5383,\n",
       " 'é¹°': 7916,\n",
       " 'å‘': 1442,\n",
       " '##éµ‘': 20921,\n",
       " 'é›': 7104,\n",
       " 'ç£…': 4829,\n",
       " 'ç“£': 4480,\n",
       " 'fpga': 9724,\n",
       " '##å‡¶': 14193,\n",
       " '##å¢œ': 14928,\n",
       " '##æ™—': 16297,\n",
       " '##ç„‰': 17240,\n",
       " 'urban': 13101,\n",
       " '##æ³µ': 16865,\n",
       " 'èŒ«': 5755,\n",
       " 'æ™•': 3238,\n",
       " 'august': 9217,\n",
       " 'ie': 8469,\n",
       " 'unity': 11897,\n",
       " 'å²': 1341,\n",
       " 'æƒ¡': 2670,\n",
       " 'ãƒˆ': 613,\n",
       " 'æ›–': 3281,\n",
       " 'ç¾¸': 5415,\n",
       " 'é–±': 7288,\n",
       " 'paypal': 8657,\n",
       " '##è¢…': 19205,\n",
       " '[unused49]': 49,\n",
       " '26': 8153,\n",
       " '##ä¾': 13955,\n",
       " '##å«”': 15125,\n",
       " '1970': 8464,\n",
       " 'å•Š': 1557,\n",
       " 'block': 10188,\n",
       " 'xddd': 12059,\n",
       " '##fi': 9864,\n",
       " '##å§¨': 15064,\n",
       " '##tan': 10105,\n",
       " '##skip': 12724,\n",
       " '##èº': 19771,\n",
       " 'aphojoy': 9869,\n",
       " '##å¨Ÿ': 15083,\n",
       " 'åˆ': 1159,\n",
       " 'æ–«': 3169,\n",
       " 'guestname': 13082,\n",
       " 'ç‰¡': 4285,\n",
       " '##æ°¡': 16761,\n",
       " '##ç›†': 17715,\n",
       " 'mwc': 12184,\n",
       " '##ves': 11084,\n",
       " 'æ·‘': 3902,\n",
       " 'å®“': 2132,\n",
       " 'é–': 7115,\n",
       " 'æ‹‹': 2862,\n",
       " 'bigbang': 11122,\n",
       " '##æ¥š': 16561,\n",
       " '##çº¯': 18340,\n",
       " 'ç ¥': 4783,\n",
       " 'è˜¸': 5985,\n",
       " 'å‘¦': 1452,\n",
       " 'è†»': 5614,\n",
       " '##è–¬': 19017,\n",
       " '##è«¦': 19377,\n",
       " '##å–«': 14661,\n",
       " 'aa': 9563,\n",
       " '##é¢¼': 20653,\n",
       " 'ä½†': 852,\n",
       " 'root': 8859,\n",
       " '##ï½¼': 21112,\n",
       " '##è´': 19616,\n",
       " 'history': 9939,\n",
       " '##æ¯†': 16733,\n",
       " '##æœ': 16419,\n",
       " 'ç™¸': 4631,\n",
       " 'å²³': 2277,\n",
       " 'tc': 12858,\n",
       " '##éª†': 20793,\n",
       " '##ç‡™': 17300,\n",
       " 'è‡»': 5638,\n",
       " 'æ‚£': 2642,\n",
       " '##ã¾ã—ã‚‡ã†': 10759,\n",
       " 'å¥„': 1935,\n",
       " 'å‡›': 1123,\n",
       " 'è¨—': 6249,\n",
       " 'share': 8697,\n",
       " 'ã¯ãŠ': 13232,\n",
       " 'é½¡': 7972,\n",
       " '##ç¹‡': 18306,\n",
       " 'fans': 11821,\n",
       " '##æƒ±': 15738,\n",
       " '##ç´³': 18227,\n",
       " '5m': 11483,\n",
       " 'ceo': 8371,\n",
       " 'è™•': 5993,\n",
       " '##ã‚¥': 13681,\n",
       " 'ã¡': 552,\n",
       " 'å€­': 963,\n",
       " '##å¦˜': 15031,\n",
       " '##æšŒ': 16319,\n",
       " 'å“ˆ': 1506,\n",
       " 'è‹»': 5742,\n",
       " 'nvidia': 9503,\n",
       " '##ç ”': 17834,\n",
       " '##ç‹': 17373,\n",
       " 'ç»Š': 5304,\n",
       " 'æ—Œ': 3182,\n",
       " '##é˜‰': 20386,\n",
       " 'nego': 11181,\n",
       " '##ä¹”': 13787,\n",
       " 'è’¹': 5893,\n",
       " '##èˆ±': 18722,\n",
       " 'install': 12461,\n",
       " '15058': 12347,\n",
       " 'ettoday': 9485,\n",
       " '##å¿–': 15618,\n",
       " '##ç‡‰': 17294,\n",
       " '##â€ ': 13498,\n",
       " '##å ': 14859,\n",
       " '##æ¡…': 16483,\n",
       " 'éµ¡': 7867,\n",
       " 'ç²§': 5115,\n",
       " 'â„¢': 362,\n",
       " 'ï½—': 8073,\n",
       " '##å¼': 14489,\n",
       " 'å™Œ': 1680,\n",
       " 'ä½”': 861,\n",
       " '##ç¢¾': 17884,\n",
       " 'ç¤': 4842,\n",
       " 'æ‹®': 2888,\n",
       " '##ã‚­': 10781,\n",
       " '##é–˜': 20338,\n",
       " 'æ‚µ': 2652,\n",
       " '##éŠ¬': 20130,\n",
       " '##æ•¦': 16199,\n",
       " '##ç¼†': 18405,\n",
       " 'ç©¢': 4951,\n",
       " '##å’¦': 14541,\n",
       " '##å‰·': 14259,\n",
       " '##æ§Œ': 16597,\n",
       " '##163': 11631,\n",
       " '[unused44]': 44,\n",
       " 'è‹”': 5726,\n",
       " 'costco': 10742,\n",
       " 'è©¢': 6273,\n",
       " '##åƒ­': 14072,\n",
       " 'å¢Š': 1865,\n",
       " '##é”': 20171,\n",
       " '##é…¢': 20044,\n",
       " '##åœœ': 14815,\n",
       " 'amoled': 11307,\n",
       " '##èƒ¸': 18598,\n",
       " '##éª°': 20814,\n",
       " 'â‹¯â‹¯': 10169,\n",
       " '##wan': 9951,\n",
       " 'ç¯': 5060,\n",
       " 'villa': 10806,\n",
       " 'evernote': 13138,\n",
       " '##è©«': 19334,\n",
       " 'powered': 10103,\n",
       " '##è³‚': 19590,\n",
       " '##æ’ƒ': 16105,\n",
       " 'åº': 2409,\n",
       " 'å½¢': 2501,\n",
       " 'é„¢': 6970,\n",
       " 'ï¹': 7998,\n",
       " '##æ¼': 16407,\n",
       " 'É¡': 199,\n",
       " 'å': 1290,\n",
       " 'èŠƒ': 5689,\n",
       " '##ç¾¹': 18473,\n",
       " 'é‰‰': 7057,\n",
       " 'Ğ¿': 247,\n",
       " '##y': 8179,\n",
       " 'è¨º': 6262,\n",
       " '##æ¨Š': 16614,\n",
       " '##éº‚': 20980,\n",
       " '##æ¿ ': 17147,\n",
       " 'èª•': 6293,\n",
       " 'è±ˆ': 6488,\n",
       " '##æ·©': 16970,\n",
       " '116': 9070,\n",
       " 'åº¹': 2436,\n",
       " '20g': 12793,\n",
       " '##vy': 11853,\n",
       " '##å©§': 15102,\n",
       " 'é“°': 7210,\n",
       " 'æ©™': 3581,\n",
       " 'çŸ—': 4755,\n",
       " 'gallery': 12595,\n",
       " '##ç˜‹': 17654,\n",
       " '##å«–': 15126,\n",
       " '##å±‚': 15288,\n",
       " 'é¸£': 7885,\n",
       " '##åº­': 15488,\n",
       " 'â™€': 486,\n",
       " 'æ­¼': 3648,\n",
       " '573032185': 9970,\n",
       " '##å—¬': 14694,\n",
       " 'é²‘': 7829,\n",
       " 'ä¼´': 845,\n",
       " 'æº±': 3986,\n",
       " ':': 131,\n",
       " '329': 11705,\n",
       " '##å¯…': 15222,\n",
       " 'è°Ÿ': 6467,\n",
       " '##ball': 11050,\n",
       " '##æˆª': 15836,\n",
       " 'é€€': 6842,\n",
       " '##ã‚Œã¯': 9170,\n",
       " 'æƒ±': 2681,\n",
       " '##é': 19939,\n",
       " '##å†': 14144,\n",
       " '##life': 10359,\n",
       " 'before': 10735,\n",
       " '##ç•œ': 17580,\n",
       " '##åµ': 14374,\n",
       " 'å¥¹': 1961,\n",
       " '##èŒ­': 18814,\n",
       " 'ãƒ¨': 634,\n",
       " 'æ¨¸': 3571,\n",
       " '421': 12873,\n",
       " '##ç…²': 17273,\n",
       " 'è½©': 6759,\n",
       " '##è•¨': 18995,\n",
       " 'ç„˜': 4188,\n",
       " '##ç¢š': 17872,\n",
       " '##é¡': 20599,\n",
       " 'emma': 12111,\n",
       " '##Â¤': 13349,\n",
       " '##æ': 15991,\n",
       " 'thai': 12967,\n",
       " 'ç¦½': 4896,\n",
       " 'è¬': 6337,\n",
       " '##è': 19141,\n",
       " 'è¬¨': 6344,\n",
       " 'é…©': 6990,\n",
       " 'é¦€': 7663,\n",
       " 'æ¸¡': 3941,\n",
       " '1903': 11295,\n",
       " 'very': 11785,\n",
       " '##è¯²': 19488,\n",
       " '##æ”»': 16179,\n",
       " '##è™½': 19063,\n",
       " 'æŠ‘': 2829,\n",
       " '230': 9111,\n",
       " '##æ®†': 16708,\n",
       " 'æ¤¿': 3499,\n",
       " 'â•š': 440,\n",
       " '186': 9833,\n",
       " 'å£¶': 1901,\n",
       " 'é¸­': 7890,\n",
       " 'ã•ã‚“': 10533,\n",
       " 'tee': 11330,\n",
       " '##æ—¶': 16255,\n",
       " 'è£': 6161,\n",
       " 'èŠ‚': 5688,\n",
       " '##å½Œ': 15550,\n",
       " 'æ´¹': 3832,\n",
       " 'crystal': 12070,\n",
       " 'çƒ¯': 4179,\n",
       " '##è…³': 18646,\n",
       " 'é²¢': 7833,\n",
       " '##è½': 19811,\n",
       " '##é‚³': 19995,\n",
       " '##é¸': 20194,\n",
       " 'è­·': 6362,\n",
       " 'å©': 1371,\n",
       " '##ï¿¥': 21123,\n",
       " 'ç–²': 4558,\n",
       " 'è¾¹': 6804,\n",
       " '##èƒ„': 18575,\n",
       " 'ç»›': 5316,\n",
       " '##ç§°': 17974,\n",
       " '##é¢—': 20635,\n",
       " '##æ¶¼': 16950,\n",
       " '##éˆ': 20104,\n",
       " 'é¥‹': 7637,\n",
       " '##dden': 13109,\n",
       " 'ç¥¥': 4872,\n",
       " 'é†š': 7009,\n",
       " '##åŠƒ': 14262,\n",
       " 'ã„…': 647,\n",
       " 'éŠ–': 7070,\n",
       " '##ãªãŸã®': 11002,\n",
       " 'ã‚’ã“': 10074,\n",
       " 'wei': 11875,\n",
       " 'ccd': 12882,\n",
       " 'ç¬': 4428,\n",
       " 'nike': 8702,\n",
       " '##äº³': 13837,\n",
       " '##é¥': 20701,\n",
       " '##ç‰Œ': 17334,\n",
       " 'é¥•': 7642,\n",
       " 'æ¥š': 3504,\n",
       " 'icecat': 9336,\n",
       " '##æ»™': 17059,\n",
       " 'ç®—': 5050,\n",
       " '##æ¶‡': 16923,\n",
       " 'ç¿¼': 5437,\n",
       " 'ç—£': 4582,\n",
       " 'take': 10985,\n",
       " '##å€†': 13998,\n",
       " 'ç•«': 4529,\n",
       " 'alexander': 11733,\n",
       " 'é²ˆ': 7827,\n",
       " '##å¢®': 14933,\n",
       " '##è£´': 19236,\n",
       " 'æºŸ': 3979,\n",
       " 'suv': 8540,\n",
       " '##n2': 12750,\n",
       " '##å€¾': 14024,\n",
       " '##ç§¸': 17975,\n",
       " '##ã¿': 9344,\n",
       " 'å‹–': 1241,\n",
       " '##ç˜©': 17666,\n",
       " '##ï¼‡': 21076,\n",
       " '##èš•': 19071,\n",
       " 'ç”©': 4501,\n",
       " 'å……': 1041,\n",
       " 'å˜¯': 1669,\n",
       " 'imsean': 12087,\n",
       " '##çŠ·': 17365,\n",
       " '##ç­±': 18093,\n",
       " '##è“': 18885,\n",
       " 'ib': 12487,\n",
       " 'ç‰¢': 4286,\n",
       " 'çª¥': 4976,\n",
       " '94': 8416,\n",
       " '##you': 12441,\n",
       " 'é¤¨': 7631,\n",
       " '##ãƒ»': 13703,\n",
       " '##ich': 11578,\n",
       " '##test': 11574,\n",
       " '##è': 19142,\n",
       " '##è†¾': 18673,\n",
       " 'è…¿': 5597,\n",
       " '##é²': 20883,\n",
       " 'express': 9865,\n",
       " 'target': 11926,\n",
       " 'æ±¶': 3746,\n",
       " 'é½': 7967,\n",
       " 'è°±': 6480,\n",
       " '##æ´²': 16885,\n",
       " 'è–¦': 5956,\n",
       " '176': 10004,\n",
       " '##è™«': 19058,\n",
       " '[unused63]': 63,\n",
       " 'eds': 12191,\n",
       " '##æ‘¯': 16098,\n",
       " 'é›': 7422,\n",
       " 'koreanmall': 9895,\n",
       " '##å£•': 14944,\n",
       " 'ç': 4711,\n",
       " 'v9': 11894,\n",
       " '##ä»‘': 13853,\n",
       " '##è¹¤': 19754,\n",
       " 'ç³¸': 5142,\n",
       " 'ç¾Š': 5399,\n",
       " '##æ—': 16235,\n",
       " 'æ': 3358,\n",
       " 'å€”': 949,\n",
       " '##è«¾': 19387,\n",
       " '##covery': 12548,\n",
       " '##è´µ': 19643,\n",
       " 'rights': 9615,\n",
       " '##ã—ã„': 10899,\n",
       " 'ç”„': 4488,\n",
       " '##å³¥': 15343,\n",
       " '##æ·º': 16980,\n",
       " 'kuso': 10881,\n",
       " 'æ°—': 3700,\n",
       " '##è§': 19281,\n",
       " 'è¯': 5836,\n",
       " '##ã¨ã„ã†': 12383,\n",
       " '##é¨': 20753,\n",
       " '##core': 11921,\n",
       " 'beta': 9861,\n",
       " '##nny': 13239,\n",
       " 'åŒ£': 1271,\n",
       " '##ç€¬': 17172,\n",
       " '220': 8796,\n",
       " '##æ‡‹': 15805,\n",
       " 'æ': 3010,\n",
       " '##æ¹«': 17021,\n",
       " 'ferragamo': 9992,\n",
       " '##æ‡ˆ': 15802,\n",
       " '##ç´™': 18215,\n",
       " '##ç¿°': 18489,\n",
       " 'æ‘': 3037,\n",
       " '##æ¦­': 16588,\n",
       " '##å•': 14463,\n",
       " 'æ¡‚': 3424,\n",
       " 'æ°¢': 3705,\n",
       " 'æ••': 3132,\n",
       " 'èµ¶': 6628,\n",
       " 'é™': 7361,\n",
       " 'æ²»': 3780,\n",
       " '##drive': 13115,\n",
       " '##â€»': 13508,\n",
       " 'fm': 9079,\n",
       " '##è† ': 18665,\n",
       " 'v1': 9074,\n",
       " 'è¡': 5834,\n",
       " 'è£¨': 6176,\n",
       " 'é’´': 7180,\n",
       " '##æº¢': 17037,\n",
       " '##åŸ‚': 14868,\n",
       " '##é¼': 21017,\n",
       " 'é“ ': 7200,\n",
       " 'æ·¡': 3909,\n",
       " 'æ°«': 3712,\n",
       " '##åˆ': 14207,\n",
       " 'è¾—': 6786,\n",
       " '##è¦†': 19265,\n",
       " 'è¶´': 6640,\n",
       " 'å½“': 2496,\n",
       " 'www': 8173,\n",
       " '227': 10543,\n",
       " 'ã‚µ': 603,\n",
       " 'è´ª': 6576,\n",
       " '237': 10775,\n",
       " '242': 11056,\n",
       " 'å¿˜': 2563,\n",
       " '##bb': 10214,\n",
       " '##æ›²': 16346,\n",
       " 'å°˜': 2212,\n",
       " '##è¾²': 19860,\n",
       " '##ã¦ã¯': 9809,\n",
       " 'é': 7126,\n",
       " 'Ï‚': 225,\n",
       " 'æ‚': 2636,\n",
       " 'ï½¯': 8086,\n",
       " 'was': 9947,\n",
       " 'å…': 1284,\n",
       " 'éƒœ': 6949,\n",
       " 'Ğ¼': 244,\n",
       " 'ï¹‚': 7997,\n",
       " '##ç«…': 18043,\n",
       " '##é‡µ': 20097,\n",
       " 'å·¢': 2338,\n",
       " 'ï¼‘ï¼’': 10351,\n",
       " '##cast': 13020,\n",
       " '##å²': 14398,\n",
       " '##æ–¹': 16232,\n",
       " '##ç‰': 17335,\n",
       " 'è¯…': 6398,\n",
       " '##æ’•': 16113,\n",
       " '##ç§£': 17967,\n",
       " 'step3': 9434,\n",
       " 'è–': 5469,\n",
       " 'æ•£': 3141,\n",
       " '##æ³»': 16868,\n",
       " 'etnews': 12870,\n",
       " 'æª—': 3594,\n",
       " 'å©': 1338,\n",
       " 'èˆ': 5650,\n",
       " '##å®°': 15210,\n",
       " 'ç±²': 5100,\n",
       " '##line': 8762,\n",
       " ...}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab\n",
    "# å¸¦\"##\"çš„æ˜¯æŠŠä¸€ä¸ªå®Œæ•´çš„è¯æ‹†æˆå¤šä¸ªå­è¯ï¼Œ\n",
    "# ä»è€Œç¼©å°è¯è¡¨ï¼Œå¾ˆå¤šè¯ä½¿ç”¨å‡ ä¸ªå­è¯æ¥ç»„æˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21128"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ç´¢å¼•è½¬æ¢: `convert_tokens_to_ids`/`convert_ids_to_tokens`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2483, 2207, 4638, 2769, 738, 3300, 1920, 3457, 2682, 106]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# å°†è¯åºåˆ—è½¬æ¢ä¸ºidåºåˆ—\n",
    "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['å¼±', 'å°', 'çš„', 'æˆ‘', 'ä¹Ÿ', 'æœ‰', 'å¤§', 'æ¢¦', 'æƒ³', '!']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# å°†idåºåˆ—è½¬æ¢ä¸ºtokenåºåˆ—\n",
    "tokens = tokenizer.convert_ids_to_tokens(ids)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'å¼± å° çš„ æˆ‘ ä¹Ÿ æœ‰ å¤§ æ¢¦ æƒ³!'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# å°†tokenåºåˆ—è½¬æ¢ä¸ºstring\n",
    "str_sen = tokenizer.convert_tokens_to_string(tokens)\n",
    "str_sen"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  å­—ç¬¦ä¸²å’Œidåºåˆ—çš„è½¬æ¢: `encode`/`decode`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 2483, 2207, 4638, 2769, 738, 3300, 1920, 3457, 2682, 106, 102]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# å°†å­—ç¬¦ä¸²è½¬æ¢ä¸ºidåºåˆ—ï¼Œåˆç§°ä¹‹ä¸ºç¼–ç \n",
    "ids = tokenizer.encode(sen, add_special_tokens=True)\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2483, 2207, 4638, 2769, 738, 3300, 1920, 3457, 2682, 106]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(sen, add_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] å¼± å° çš„ æˆ‘ ä¹Ÿ æœ‰ å¤§ æ¢¦ æƒ³! [SEP]'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# å°†idåºåˆ—è½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼Œåˆç§°ä¹‹ä¸ºè§£ç \n",
    "str_sen = tokenizer.decode(ids, skip_special_tokens=False)\n",
    "str_sen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'å¼± å° çš„ æˆ‘ ä¹Ÿ æœ‰ å¤§ æ¢¦ æƒ³!'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(ids, skip_special_tokens=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### å¡«å……ä¸æˆªæ–­: `padding`/`truncation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 2483, 2207, 4638, 2769, 738, 3300, 1920, 3457, 2682, 106, 102, 0, 0, 0]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# å¡«å……\n",
    "ids = tokenizer.encode(sen, padding=\"max_length\", max_length=15)\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 2483, 2207, 4638, 102]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# æˆªæ–­\n",
    "ids = tokenizer.encode(sen, max_length=5, truncation=True)\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 2483, 2207, 4638, 2769, 738, 3300, 1920, 3457, 2682, 106, 102]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 2483, 2207, 4638, 2769, 102, 2483, 2207, 4638, 2769, 738, 102]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ä¸¤ä¸ªéƒ½æˆªæ–­\n",
    "tokenizer.encode([sen, sen], max_length=12, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101,\n",
       " 2483,\n",
       " 2207,\n",
       " 4638,\n",
       " 2769,\n",
       " 738,\n",
       " 3300,\n",
       " 1920,\n",
       " 102,\n",
       " 2483,\n",
       " 2207,\n",
       " 4638,\n",
       " 2769,\n",
       " 738,\n",
       " 3300,\n",
       " 1920,\n",
       " 3457,\n",
       " 2682,\n",
       " 106,\n",
       " 102]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# åªæˆªæ–­äº†ç¬¬ä¸€ä¸ª\n",
    "tokenizer.encode([sen, sen], max_length=20, truncation=\"only_first\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### å…¶ä»–è¾“å…¥éƒ¨åˆ†: `attention_mask`/`token_type_ids`\n",
    "\n",
    "* `attention_mask`ï¼šæ ‡è®°å“ªäº›éƒ¨åˆ†çš„tokenæ˜¯æœ‰æ„ä¹‰çš„ï¼Œå“ªäº›éƒ¨åˆ†æ˜¯paddingçš„\n",
    "\n",
    "* `token_type_ids`ï¼šæ ‡è®°å“ªäº›éƒ¨åˆ†çš„tokenå±äºç¬¬ä¸€ä¸ªå¥å­ï¼Œå“ªäº›éƒ¨åˆ†çš„tokenå±äºç¬¬äºŒä¸ªå¥å­"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 2483, 2207, 4638, 2769, 738, 3300, 1920, 3457, 2682, 106, 102, 0, 0, 0]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = tokenizer.encode(sen, padding=\"max_length\", max_length=15)\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([101, 2483, 2207, 4638, 2769, 738, 3300, 1920, 3457, 2682, 106, 102, 0, 0, 0],\n",
       " [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# attention_mask:\n",
    "# 0è¡¨ç¤ºpaddingï¼Œ1è¡¨ç¤ºépadding\n",
    "# token_type_ids:\n",
    "# 0è¡¨ç¤ºç¬¬ä¸€ä¸ªå¥å­ï¼Œ1è¡¨ç¤ºç¬¬äºŒä¸ªå¥å­\n",
    "# å¯¹äºå•å¥ä»»åŠ¡ï¼Œtoken_type_idså…¨ä¸º0\n",
    "# å¯¹äºåŒå¥ä»»åŠ¡ï¼Œtoken_type_idsçš„å‰åŠéƒ¨åˆ†ä¸º0ï¼ŒååŠéƒ¨åˆ†ä¸º1\n",
    "attention_mask = [1 if idx != tokenizer.pad_token_id else 0 for idx in ids]\n",
    "token_type_ids = [0] * len(ids)\n",
    "ids, attention_mask, token_type_ids"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### å¿«é€Ÿè°ƒç”¨æ–¹å¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 2483, 2207, 4638, 2769, 738, 3300, 1920, 3457, 2682, 106, 102, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer.encode_plus(sen, padding=\"max_length\", max_length=15)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 2483, 2207, 4638, 2769, 738, 3300, 1920, 3457, 2682, 106, 102, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(sen, padding=\"max_length\", max_length=15)\n",
    "inputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### å¤„ç†batchæ•°æ®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 2483, 2207, 4638, 2769, 738, 3300, 1920, 3457, 2682, 102], [101, 3300, 3457, 2682, 6443, 6963, 749, 679, 6629, 102], [101, 6841, 6852, 3457, 2682, 4638, 2552, 8024, 3683, 3457, 2682, 3315, 6716, 8024, 3291, 1377, 6586, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sens = [\"å¼±å°çš„æˆ‘ä¹Ÿæœ‰å¤§æ¢¦æƒ³\", \"æœ‰æ¢¦æƒ³è°éƒ½äº†ä¸èµ·\", \"è¿½é€æ¢¦æƒ³çš„å¿ƒï¼Œæ¯”æ¢¦æƒ³æœ¬èº«ï¼Œæ›´å¯è´µ\"]\n",
    "res = tokenizer(sens)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30.9 ms, sys: 0 ns, total: 30.9 ms\n",
      "Wall time: 30.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# å•æ¡å¾ªç¯å¤„ç†\n",
    "for i in range(1000):\n",
    "    tokenizer(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36.1 ms, sys: 0 ns, total: 36.1 ms\n",
      "Wall time: 6.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# å¤„ç†batchæ•°æ®\n",
    "res = tokenizer([sen] * 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='./roberta_tokenizer/', vocab_size=21128, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fast / Slow Tokenizer\n",
    "Fast Tokenizerï¼š\n",
    "\n",
    "* åŸºäºRustå®ç°ï¼Œé€Ÿåº¦å¿«\n",
    "\n",
    "* offsets_mappingã€word_ids\n",
    "\n",
    "Slow Tokenizerï¼š\n",
    "\n",
    "* åŸºäºpythonå®ç°ï¼Œé€Ÿåº¦æ…¢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen = \"å¼±å°çš„æˆ‘ä¹Ÿæœ‰å¤§Dreaming!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='uer/roberta-base-finetuned-dianping-chinese', vocab_size=21128, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"uer/roberta-base-finetuned-dianping-chinese\"\n",
    ")\n",
    "fast_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizer(name_or_path='uer/roberta-base-finetuned-dianping-chinese', vocab_size=21128, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slow_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"uer/roberta-base-finetuned-dianping-chinese\", use_fast=False\n",
    ")\n",
    "slow_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 309 ms, sys: 2.74 ms, total: 312 ms\n",
      "Wall time: 312 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# å•æ¡å¾ªç¯å¤„ç†\n",
    "for i in range(10000):\n",
    "    fast_tokenizer(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 819 ms, sys: 1.92 ms, total: 821 ms\n",
      "Wall time: 823 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# å•æ¡å¾ªç¯å¤„ç†\n",
    "for i in range(10000):\n",
    "    slow_tokenizer(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 323 ms, sys: 15.1 ms, total: 338 ms\n",
      "Wall time: 88.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# å¤„ç†batchæ•°æ®\n",
    "res = fast_tokenizer([sen] * 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 672 ms, sys: 0 ns, total: 672 ms\n",
      "Wall time: 672 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# å¤„ç†batchæ•°æ®\n",
    "res = slow_tokenizer([sen] * 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 2483, 2207, 4638, 2769, 738, 3300, 1920, 10252, 8221, 106, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'offset_mapping': [(0, 0), (0, 1), (1, 2), (2, 3), (3, 4), (4, 5), (5, 6), (6, 7), (7, 12), (12, 15), (15, 16), (0, 0)]}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sen = \"å¼±å°çš„æˆ‘ä¹Ÿæœ‰å¤§Dreaming!\"\n",
    "# return_offsets_mapping: dreamingè¢«åˆ†ä¸ºdreamå’Œing\n",
    "# word_idsæŒ‡çš„æ˜¯å¯¹åº”åŸå¥çš„å“ªä¸ªè¯ï¼Œdreamå¯¹åº”ç¬¬7è¯ï¼Œingä¹Ÿæ˜¯\n",
    "# offsets_mappingæŒ‡çš„æ˜¯æ¯ä¸ªtokenå¯¹åº”çš„indexï¼Œ(7,12)æŒ‡çš„æ˜¯dreamï¼Œ(12,15)æŒ‡çš„æ˜¯ingï¼Œ(15,16)ä¸º!\n",
    "inputs = fast_tokenizer(sen, return_offsets_mapping=True)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, 0, 1, 2, 3, 4, 5, 6, 7, 7, 8, None]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.word_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "return_offset_mapping is not available when using Python tokenizers. To use this feature, change your tokenizer to one deriving from transformers.PreTrainedTokenizerFast. More information on available tokenizers at https://github.com/huggingface/transformers/pull/2674",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[43mslow_tokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43msen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/App/miniconda3/envs/transformers/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2945\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2943\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_target_context_manager:\n\u001b[1;32m   2944\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_input_mode()\n\u001b[0;32m-> 2945\u001b[0m     encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mall_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2946\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2947\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_target_mode()\n",
      "File \u001b[0;32m~/App/miniconda3/envs/transformers/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3053\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m   3032\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_encode_plus(\n\u001b[1;32m   3033\u001b[0m         batch_text_or_text_pairs\u001b[38;5;241m=\u001b[39mbatch_text_or_text_pairs,\n\u001b[1;32m   3034\u001b[0m         add_special_tokens\u001b[38;5;241m=\u001b[39madd_special_tokens,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3050\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3051\u001b[0m     )\n\u001b[1;32m   3052\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3053\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3054\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3055\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3056\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3057\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3058\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3059\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3060\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3061\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3062\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3063\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3064\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3065\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3066\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3067\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3068\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3069\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3070\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3071\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3072\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3073\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/App/miniconda3/envs/transformers/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3127\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   3117\u001b[0m \u001b[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[1;32m   3118\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[1;32m   3119\u001b[0m     padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[1;32m   3120\u001b[0m     truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3124\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3125\u001b[0m )\n\u001b[0;32m-> 3127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3130\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3132\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3133\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3137\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3141\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3142\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3145\u001b[0m \u001b[43m    \u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msplit_special_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3146\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3147\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/App/miniconda3/envs/transformers/lib/python3.10/site-packages/transformers/tokenization_utils.py:780\u001b[0m, in \u001b[0;36mPreTrainedTokenizer._encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    774\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    775\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not valid. Should be a string, a list/tuple of strings or a list/tuple of\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    776\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m integers.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    777\u001b[0m             )\n\u001b[1;32m    779\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_offsets_mapping:\n\u001b[0;32m--> 780\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    781\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn_offset_mapping is not available when using Python tokenizers. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    782\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo use this feature, change your tokenizer to one deriving from \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    783\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransformers.PreTrainedTokenizerFast. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMore information on available tokenizers at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    785\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://github.com/huggingface/transformers/pull/2674\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    786\u001b[0m     )\n\u001b[1;32m    788\u001b[0m first_ids \u001b[38;5;241m=\u001b[39m get_input_ids(text)\n\u001b[1;32m    789\u001b[0m second_ids \u001b[38;5;241m=\u001b[39m get_input_ids(text_pair) \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: return_offset_mapping is not available when using Python tokenizers. To use this feature, change your tokenizer to one deriving from transformers.PreTrainedTokenizerFast. More information on available tokenizers at https://github.com/huggingface/transformers/pull/2674"
     ]
    }
   ],
   "source": [
    "inputs = slow_tokenizer(sen, return_offsets_mapping=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç‰¹æ®ŠTokenizerçš„åŠ è½½\n",
    "\n",
    "ä¸åŒæ¨¡å‹å¯¹åº”çš„åˆ†è¯å™¨çš„æ•ˆæœä¹Ÿä¸åŒï¼Œæœ‰çš„ä¼šåœ¨ç»“å°¾åŠ ä¸Š`<\\s>`ï¼Œæœ‰çš„ä¼šåœ¨å¼€å¤´åŠ `<CLS>`åœ¨ç»“å°¾åŠ `<EOS>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the legacy behaviour of the <class 'transformers_modules.Skywork.Skywork-13B-base.bc35915066fbbf15b77a1a4a74e9b574ab167816.tokenization_skywork.SkyworkTokenizer'>. This means that tokens that come after special tokens will not be properly handled. \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SkyworkTokenizer(name_or_path='Skywork/Skywork-13B-base', vocab_size=65519, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# æ–°ç‰ˆæœ¬çš„transformersï¼ˆ>4.34ï¼‰ï¼ŒåŠ è½½ THUDM/chatglm ä¼šæŠ¥é”™ï¼Œå› æ­¤è¿™é‡Œæ›¿æ¢ä¸ºäº†å¤©å®«çš„æ¨¡å‹\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"Skywork/Skywork-13B-base\", trust_remote_code=True\n",
    ")\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('skywork_tokenizer/tokenizer_config.json',\n",
       " 'skywork_tokenizer/special_tokens_map.json',\n",
       " 'skywork_tokenizer/tokenizer.model',\n",
       " 'skywork_tokenizer/added_tokens.json')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(\"skywork_tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"skywork_tokenizer\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>å¼±å°çš„æˆ‘ä¹Ÿæœ‰å¤§Dreaming!'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer.encode(sen))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
